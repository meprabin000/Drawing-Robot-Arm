{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790d8e72",
   "metadata": {},
   "source": [
    "## Spam Email Detection using Naive Bayes technique ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab9abb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading file from dataset\n",
    "df = pd.read_table('smsspamcollection/SMSSpamCollection', sep='\\t', names=['label','sms_message'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076cfe1",
   "metadata": {},
   "source": [
    "### Data Preprocessing ###\n",
    "\n",
    "Converting the labels to binary variables for easier computation {'ham':0,'spam':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f287063b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'ham':0,'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee5eb7",
   "metadata": {},
   "source": [
    "Now that our labels are ready, I will use bag of words (BoW) model for classification. In the BoW model, each sms_message will be broken down to individual terms. Each term will than be transformed to lowercase and then broken into tokens such that during classification, the word such as hello and Hello will be treated same. For that, I will use CountVectorizer from sklearn.feature_extraction.text.\n",
    "\n",
    "Before that, I will have to split the dataset into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91768daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 5572\n",
      "Number of rows in the training set: 4179\n",
      "Number of rows in the test set: 1393\n"
     ]
    }
   ],
   "source": [
    "# split the training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)\n",
    "\n",
    "# visualizing the counts of training and testing\n",
    "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3d20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. No fitting is done so, X_test will not be stored in count_vector\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be64ea",
   "metadata": {},
   "source": [
    "### Model Implementation ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88686cb",
   "metadata": {},
   "source": [
    "Now that our data set ready for classification, we will use naive bayes classifier. Specifically, multinomial Naive bayes classifying algorithm will be used because it is suitable for classification discrete features like in our case where we are using word count for classification. One thing to note is that Naive Bayes Classifier assumes that each feature is independent of the other, which may not necessarily be the case here be because if we see the word \"free\", it is very likely to see another word \"money\" or \"cash\". However, assuming independence makes our model simple and works well on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59edd241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65424682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a prediction on the testing data\n",
    "predictions = naive_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57645ace",
   "metadata": {},
   "source": [
    "### Model Evaluation ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4590382",
   "metadata": {},
   "source": [
    "Our model is ready. Now, it is time to evaluate how well our model performed in the testing set. We will evaluate following metrics to understand the model performance:\n",
    "1. accuracy_score: ratio of correct predictions over incorrect predictions.\n",
    "2. precision_score: proportion of messages we classified as spam that were actually spam.\n",
    "3. recall_score: proportion of messages that were actually spam were classified as spam by our model.\n",
    "\n",
    "precision_score and recall_score might sound similar but they are not. \n",
    "precision_score is (true positives / (true positives + false positives)) whereas\n",
    "recall_score is the sensitivity measure, which is (true positives / (true positives + false negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de8a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9885139985642498\n",
      "Precision score:  0.9720670391061452\n",
      "Recall score:  0.9405405405405406\n",
      "F1 score:  0.9560439560439562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions)))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions)))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7435c",
   "metadata": {},
   "source": [
    "Bingo !!! Our classification model is ready. One of the advantages of using Naive Bayes classifier for these type of problems is for its ability to handle extremely large feature sets such as in our problem where each word is treated as a feature. Compared to neural network and decision trees, this classification is extremely fast and overfitting of the data is rarely the case.\n",
    "\n",
    "Therefore, we have succesfully designed a model that can efficiently predict whether an SMS message is spam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b912e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
